# ----------------------------
# PLATFORM MODE
# ----------------------------
# This flag controls the embedding strategy used for retrieval:
# LOCAL  → sentence-transformers embeddings (no external API calls for retrieval)
# CLOUD  → OpenAI embeddings API (recommended for small cloud instances like Render)
#
# Note: LLM provider selection for answer generation is per-request via `llm_provider`.
PLATFORM=LOCAL

# ----------------------------
# OpenAI Configuration
# ----------------------------
OPENAI_API_KEY=your_openai_key_here
OPENAI_MODEL=gpt-4o-mini  # or any latest small model

# ----------------------------
# Gemini Configuration
# ----------------------------
GEMINI_API_KEY=your_gemini_key_here
GEMINI_MODEL=gemini-3-flash-preview  # or any latest small model

# ----------------------------
# Ollama Configuration
# ----------------------------
# Only used in LOCAL mode
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:1b

# ----------------------------
# RAG Settings
# ----------------------------
# CLOUD (PLATFORM=CLOUD): OpenAI embedding model
EMBEDDING_MODEL=text-embedding-3-small
# LOCAL (PLATFORM=LOCAL): sentence-transformers model name
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
TOP_K=3
